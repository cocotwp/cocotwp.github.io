---
layout: article
title: Spark 基础入门
tags: 
- Spark
- 黑马
toc: true
---

## 第1章 Spark 框架概述

### Spark 是什么

[Apache Spark](https://spark.apache.org) 是一个多语言引擎，用于在单节点机器或集群上执行数据工程、数据科学和机器学习。\
Apache Spark™ is a multi-language engine for executing data engineering, data science, and machine learning on single-node machines or clusters.

### Spark 有哪些特性

- 批处理/流式数据（Batch/streaming data）
- SQL分析（SQL analytics）
- 弹性数据科学（Data science at scale）
- 机器学习（Machine learning）

### Spark 有哪些模块

核心SparkCore、SQL计算（SparkSQL）、流计算（SparkStreaming）、图计算（GraphX）、机器学习（MLib）

### Spark 的运行模式

- 本地模式（Local）
- 集群模式（StandAlone、YARN、K8S）
- 云模式

### Spark 的运行角色（对比 YARN）

- Master：集群资源管理（类同 ResourceManager）
- Worker：单机资源管理（类同 NodeManager）
- Driver：单任务管理者（类同 ApplicationMaster）
- Executor：单任务执行者（类同 YARN 容器内的 Task）

## 第2章 Spark 环境搭建-Local

**略**

## 第3章 Spark 环境搭建-Standalone

### Standalone 架构

在 *Standalone集群* 上主要有3类进程：
- 主节点 Master：管理整个集群资源各个任务的 Driver；
- 从节点 Workers：管理每个机器的资源，分配对应的资源来运行 Executor（Task）；
- 历史服务器 HistoryServer（可选）：Spark Application 运行完成以后，保存事件日志数据至 HDFS，启动 HistoryServer 可以查看应用运行相关信息。

### Standalone 环境安装操作

**略**

### Spark 应用架构

<div align=center>
	<img src="https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/Spark执行阶段.png" alt="spark执行阶段"/>
</div>

<!-- ![spark执行阶段](https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/Spark执行阶段.png) -->

用户应用程序从最开始的提交到最终的计算执行，需要经历一下几个阶段：
1. 用户程序创建 `SparkContext` 时，新创建的 `SparkContext` 实例会连接到 `ClusterManager`。`Cluster Manager` 会根据用户提交时设置的 CPU 和内存等信息为本次提交分配计算资源，启动 `Executor`；
2. `Driver` 会将用户程序划分为不同的执行阶段 Stage，每个执行阶段 Stage 由一组完全相同 Task 组成，这些 Task 分别作用于待处理数据的不同分区。在阶段划分完成和 Task 创建后， `Driver` 会向 `Executor` 发送 Task；
3. `Executor` 在接收到 Task 后，会下载 Task 的运行时依赖，在准备好 Task 的执行环境后，会开始执行 Task，并且将 Task 的运行状态汇报给 `Driver`；
4. `Driver` 会根据收到的 Task 的运行状态来处理不同的状态更新。Task 分为两种：一种是 Shuffle Map Task，它实现数据的重新洗牌，洗牌的结果保存到 `Executor` 所在节点的文件系统中；另外一种是 Result Task，它负责生成结果数据；
5. `Driver` 会不断地调用 Task，将Task发送到 `Executor` 执行，在所有的Task 都正确执行或者超过执行次数的限制仍然没有执行成功时停止。

### Spark 运行层次结构

Spark Application 程序运行时三个核心概念：`Job`、`Stage`、`Task`，说明如下：
- Job：由多个 Task 的并行计算部分，一般 Spark 中的 action 操作(如 save、collect，后面进一步说明)，会 生成一个 Job。
- Stage：Job 的组成单位，一个 Job 会切分成多个 Stage，Stage 彼此之间相互依赖顺序执行，而每个 Stage 是多个 Task 的集合，类似 map 和 reduce stage。
- Task：被分配到各个 Executor 的单位工作内容，它是 Spark 中的最小执行单位，一般来说有多少个 Paritition (物理层面的概念，即分支可以理解为将数据划分成不同 部分并行处理)，就会有多少个 Task，每个 Task 只会处理单一分支上的数据。

## 第4章 Spark 环境搭建-Standalone HA

Spark Standalone 集群是 `Master-Slaves` 架构的集群模式，和大部分的 Master-Slaves 结构集群一样，存在着 Master 单点故障（SPOF）的问题。

### 基于 Zookeeper 的 HA

ZooKeeper 的 Standby Master（Standby Masters with ZooKeeper）

`ZooKeeper` 提供了一个 Leader Election 机制，利用这个机制可以保证虽然集群存在多个 Master，但是只有一个 Active 的，其他的都是 Standby 状态。当 Active 的 Master 出现故障时，另外的一个 Standby Master 会被选举出来。由于集群的信息，包括 Worker、Driver 和 Application 的信息都已经持久化道文件系统中，因此在切换的过程中只会影响新的 Job 提交，对于正在进行的 Job 没有任何影响。

`ZooKeeper` 的集群整体架构如下图：

![基于Zookeeper实现HA](https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/基于Zookeeper实现HA.png)

## 第5章 环境搭建-Spark on YARN

`YARN` 本身是一个资源调度框架，负责对运行在内部的计算框架进行资源调度管理。作为典型的计算框架，Spark 本身也是直接运行在 YARN 中，并接受 `YARN` 的调度。

### SparkOnYarn 本质

![Spark on YARN](https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/Spark_on_YARN.png)

- `Master` 角色由 YARN 的 `ResourceManager` 担任
- `Worker` 角色由 YARN 的 `NodeManager` 担任
- `Driver` 角色运行在 **YARN容器** 内或提交任务的 **客户端进程中** 
- `Executor` 运行在 **YARN 提供的容器**内

### 部署模式 DeployMode

Spark on YARN 有两种运行模式（区别在于 `Driver` 运行的位置）：

- Cluster 模式：Driver 运行在 YARN 容器内部，和 ApplicationMaster 在同一个容器内

![Cluster模式](https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/Cluster模式.png)

- Client 模式：Driver 运行在客户端进程中，比如 Driver 运行在 spark-submit 程序的进程中

![Client模式](https://raw.githubusercontent.com/cocotwp/cocotwp.github.io/master/assets/images/part1/Client模式.png)

